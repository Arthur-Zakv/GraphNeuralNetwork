{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data, Batch, DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3bdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGN(nn.Module):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    T : time neighbourhoood\n",
    "    d_t : dimension of encoded time\n",
    "\n",
    "    d_v : dimension of node \n",
    "    d_e : dimension of edge \n",
    "    d_h : dimension of node embedded state\n",
    "    d_s : dimension of node memory state\n",
    "    d_rm_n : dimension of raw-message from node-wise event\n",
    "    d_rm_i : dimension of raw_message from interaction event\n",
    "\n",
    "    l : number of GAT layers\n",
    "    k : number of attention heads\n",
    "    d_q : dimension of query\n",
    "    d_c : dimension of concatenated neighbours\n",
    "    n : maximum number of neighbours per node used in GAT (take the last n edge events)\n",
    "\n",
    "    rm : raw messages\n",
    "    om : old messages (= m : messages)\n",
    "    am : aggregated messages\n",
    "    \n",
    "    raw_message_store :  v_i, e_ij -- stores node_wise events v_i and interaction events e_ij at every timestep\n",
    "                         For a directed edge enter only (i,j), for undirected (i,j) and (j,i) in interaction events\n",
    "    memory :             s_i -- stores memory vector s_i for every node\n",
    "    message_function_v : msg_v() -- message to node that has a node_wise_event\n",
    "    message_function_e : msg_e() -- message to both nodes in an interaction_event\n",
    "    message_aggregator : agg() -- aggregates all past messages before using them to update memory\n",
    "    memory_updater :     mem() -- use aggregated message to update the memory\n",
    "    phi :                phi() -- time embedding\n",
    "    embedder :           h_i -- temporal graph attention to embedd nodes\n",
    "    decoder :            p_e_ij -- edge probabilities \n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    train_loss :         BCE based on negative log likelihood of only those edges, that we put in as input for the next timestep.\n",
    "    predict_links :      Predict all edges (bidirectional, (i,j) and (j,i)) of the graph for the next timestep (not just new edges).\n",
    "    add_batch_to_graph : Update the graph with new nodes and edges events (add / delete / modify)\n",
    "    \"\"\"\n",
    "    def __init__(self, G, TGN_hyperparams):\n",
    "        super(TGN, self).__init__()\n",
    "     \n",
    "        l = TGN_hyperparams['l'] \n",
    "        k = TGN_hyperparams['k'] \n",
    "        n = TGN_hyperparams['n']\n",
    "        d_t = TGN_hyperparams['d_t'] \n",
    "        d_v = TGN_hyperparams['d_v'] \n",
    "        d_e = TGN_hyperparams['d_e'] \n",
    "        d_m = TGN_hyperparams['d_m']\n",
    "        d_h = d_v\n",
    "        d_s = d_v\n",
    "        d_rm_v = d_s + 1 + d_v\n",
    "        d_rm_e = 2*d_s + 1 + d_e\n",
    "        d_q = d_h + d_t\n",
    "        d_c = d_h + d_t + d_e\n",
    "        \n",
    "        self.raw_message_store = RawMessageStore(G)\n",
    "        self.memory = Memory(N_0, d_s)\n",
    "        self.message_function_v = MessageFunction(d_rm_v, d_m)\n",
    "        self.message_function_e = MessageFunction(d_rm_e, d_m)\n",
    "        self.message_aggregator = get_MessageAggregator(reduction = 'mean')\n",
    "        self.memory_updater = MemoryUpdater(d_m, d_s)\n",
    "        self.phi = time2vec(d_t)\n",
    "        self.embedder = TemporalGraphAttention(l, k, n, d_c, d_h, d_t)\n",
    "        self.decoder = LinkPrediction()\n",
    "        \n",
    "        \n",
    "    def old_messages(self):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        -\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        old_messages : dict( int : {torch.tensor[1] : torch.tensor[d_m]})\n",
    "                       dict( i : {t : m})\n",
    "        \"\"\"\n",
    "        old_messages = dict()\n",
    "        v = self.raw_message_store.node_wise_events\n",
    "        e = self.raw_message_store.interaction_events_individual\n",
    "        \n",
    "        for i in v.keys():\n",
    "            s_i = self.memory.S[i]\n",
    "            v_i_t = v[i]\n",
    "            e_i_t = e[i]\n",
    "\n",
    "            old_messages_i = defaultdict(list)\n",
    "            for t, v_i in v_i_t.items():\n",
    "                m_i = self.message_function_v([s_i, t, v_i])\n",
    "                old_messages_i[t].append(m_i)\n",
    "            for j, e_ij_t in e_i_t.items():\n",
    "                for t, (e_ij, delta_t) in e_ij_t.items():\n",
    "                    s_j = self.memory.S[j]\n",
    "                    m_i = self.message_function_e([s_i, s_j, t, e_ij])\n",
    "                    old_messages_i[t].append(m_i)\n",
    "            old_messages[i] = old_messages_i\n",
    "        return old_messages\n",
    "\n",
    "    \n",
    "    def aggregated_messages(self, old_messages):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        om : dict( int : {torch.tensor[1] : torch.tensor[d_m]})\n",
    "             dict( i : {t : m})\n",
    "             \n",
    "        Returns\n",
    "        -------\n",
    "        am : dict( int : torch.tensor[d_m] )\n",
    "             dict( i : am_i)\n",
    "        \"\"\"\n",
    "        am = self.message_aggregator(old_messages)\n",
    "        return am\n",
    "    \n",
    "    \n",
    "    def update_memory(self, am):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        am : dict( int : torch.tensor[d_m] )\n",
    "             dict( i : am_i)\n",
    "             \n",
    "        Returns\n",
    "        -------\n",
    "        -\n",
    "        \"\"\"\n",
    "        S_next = self.memory_updater(am, self.memory.S)\n",
    "        self.memory(S_next)\n",
    "       \n",
    "    \n",
    "    def init_hidden_states(self):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        -\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        \"\"\"\n",
    "        N = len(self.memory.S)\n",
    "        h = list()\n",
    "        for i in range(N):\n",
    "            s_i = self.memory.S[i]\n",
    "            t = list(self.raw_message_store.node_wise_events[i].keys())[-1]\n",
    "            v_i = self.raw_message_store.node_wise_events[i][t]\n",
    "            h_i = s_i + v_i\n",
    "            h.append(h_i)\n",
    "        h = torch.stack(h, dim = 0)\n",
    "        return h\n",
    "        \n",
    "        \n",
    "    def embedd(self, t):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        t : torch.tensor[1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        \"\"\"\n",
    "        h = self.init_hidden_states()\n",
    "        e = self.raw_message_store.interaction_events_individual\n",
    "        phi_0 = self.phi.t0()\n",
    "        phi_t = self.phi.t_minus_tj(e, t)\n",
    "        h = self.embedder(h, phi_t, phi_0, e)\n",
    "        return h\n",
    "       \n",
    "        \n",
    "    def loss_fn(self, p_e_ij, e_ij):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        p_e_ij: torch.tensor[E_new, 1]\n",
    "        e_ij: torch.tensor[E_new, 1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        BCE : torch.tensor[1]\n",
    "        \n",
    "        \"\"\"\n",
    "        ones = torch.ones_like(p_e_ij)\n",
    "        \n",
    "        BCE = - (e_ij * torch.log(p_e_ij) + (ones - e_ij) * torch.log(ones - p_e_ij)).sum(dim = 0)\n",
    "        return BCE\n",
    "        \n",
    "        \n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        t : torch.tensor[1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        \"\"\"\n",
    "        om = self.old_messages()\n",
    "        am = self.aggregated_messages(om)\n",
    "        self.update_memory(am)\n",
    "        h = self.embedd(t)\n",
    "        return h\n",
    "    \n",
    "    \n",
    "    def train_loss(self, interaction_events):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        interaction_events : list(  ((int,int), torch.tensor[d_e], torch.tensor[1]), ... )\n",
    "                             list(  ((j,i),     e_ij,              t             ), ... )\n",
    "                             \n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.tensor[1]\n",
    "        \"\"\"\n",
    "        t = interaction_events[0][-1]\n",
    "        h = self(t)\n",
    "        e_ids_event = [e_id for (e_id,_,_) in interaction_events]\n",
    "        e_ij_event  = torch.stack([e_ij for (_,e_ij, _) in interaction_events], dim = 0)\n",
    "        p_e_ij_event = self.decoder.probs(h, e_ids_event)\n",
    "        loss = self.loss_fn(p_e_ij_event, e_ij_event)\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def predict_links(self, t):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        t : torch.tensor[1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pred_edge_index : torch.tensor[2, E]\n",
    "            no self connection, but directed connections\n",
    "            contains predicted edges of entire graph, not just new ones\n",
    "        \"\"\"\n",
    "        h = self(t)\n",
    "        pred_edge_index = self.decoder.pred_edge_index(h)\n",
    "        return pred_edge_index\n",
    "    \n",
    "    \n",
    "    def add_batch_to_graph(self, node_wise_events = [], interaction_events = []):\n",
    "        \"\"\"process new nodes and edges: (add / modify / remove)\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        node_wise_events   : list(  (int,       torch.tensor[d_v], torch.tensor[1]), ... )\n",
    "                             list(  (i,         v_i,               t             ), ... )\n",
    "                             \n",
    "        interaction_events : list(  ((int,int), torch.tensor[d_e], torch.tensor[1]), ... )\n",
    "                             list(  ((j,i),     e_ij,              t             ), ... )\n",
    "                             \n",
    "        Returns\n",
    "        -------\n",
    "        -\n",
    "        \"\"\"\n",
    "        self.raw_message_store.save_new_raw_messages(node_wise_events, interaction_events)\n",
    "        for i, v_i, _ in node_wise_events:\n",
    "            # remove node\n",
    "            if v_i.nonzero().sum() == 0:\n",
    "                self.raw_message_store.remove_node(i)\n",
    "            # add node\n",
    "            if i > (len(self.memory.S)-1):\n",
    "                self.memory.add_node()\n",
    "                \n",
    "        # remove edge\n",
    "        for i, e_i_t in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7037239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawMessageStore(nn.Module):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    node_wise_events   : dict(  { int :       {torch.tensor[1] : torch.tensor[d_v]}                   }  )\n",
    "                         dict(  { i :         {t              : v_i              }                    }  )\n",
    "                         \n",
    "    interaction_events : dict(  { (int,int) : {torch.tensor[1] : (torch.tensor[d_e]}, torch.tensor[1]) }  })\n",
    "                         dict(  { (j,i) :     {t               : (e_ij,               delta_t        ) }  })\n",
    "                         \n",
    "    interaction_events_individual :\n",
    "                         dict(  { int : { int : {torch.tensor[1] : (torch.tensor[d_e]}, torch.tensor[1]) }  })\n",
    "                         dict(  { i   : { j   : {t :               (e_ij,               delta_t        ) }  })    \n",
    "    \"\"\"\n",
    "    def __init__(self, G):\n",
    "        super(RawMessageStore, self).__init__()\n",
    "        \n",
    "        self.init_raw_messages(G)\n",
    "    \n",
    "    def init_raw_messages(self, graph):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        graph : torch_geometric.data.Data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Initialize RawMessageStore\n",
    "        \"\"\"\n",
    "        self.node_wise_events = defaultdict(dict)\n",
    "        self.interaction_events = defaultdict(dict)\n",
    "        self.interaction_events_individual = defaultdict(lambda: defaultdict(dict))\n",
    "        \n",
    "        t_0 = torch.tensor([0.])\n",
    "        node_wise_events = [(i, v_i, t_0) for (i, v_i) in enumerate(graph['x'])]\n",
    "        interaction_events = list()\n",
    "        for (edge_id, e_ij) in enumerate(graph['edge_attr']):\n",
    "            j = graph['edge_index'][0, edge_id].item()\n",
    "            i = graph['edge_index'][1, edge_id].item()\n",
    "            interaction_events.append(((j,i), e_ij, t_0))\n",
    "        self.save_new_raw_messages(node_wise_events, interaction_events)\n",
    "        \n",
    " \n",
    "    def save_new_raw_messages(self, node_wise_events = [], interaction_events = []):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        node_wise_events   : list(  (int,       torch.tensor[d_v], torch.tensor[1]), ... )\n",
    "                             list(  (i,         v_i,               t             ), ... )\n",
    "                             \n",
    "        interaction_events : list(  ((int,int), torch.tensor[d_e], torch.tensor[1]), ... )\n",
    "                             list(  ((j,i),     e_ij,              t             ), ... )\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Update RawMessageStore\n",
    "        \"\"\"\n",
    "        for i, v_i, t in node_wise_events:\n",
    "            self.node_wise_events[i][t] = v_i\n",
    "            \n",
    "        for (j,i), e_ij, t in interaction_events:\n",
    "            # Interaction event as edge (j,i)\n",
    "            ###################################################\n",
    "            if not self.interaction_events[(j,i)]:\n",
    "                delta_t = torch.tensor(0.)\n",
    "            else:\n",
    "                t_prev = list(self.interaction_events[(j,i)].keys())[-1]\n",
    "                delta_t = t - t_prev    \n",
    "            self.interaction_events[(j,i)][t] = e_ij, delta_t\n",
    "            \n",
    "            # Interaction event per node, per neigbour [i][j]\n",
    "            ###################################################\n",
    "            if not self.interaction_events_individual[i][j]:\n",
    "                delta_t = torch.tensor(0.)\n",
    "            else:\n",
    "                t_prev = list(self.interaction_events_individual[i][j].keys())[-1]\n",
    "            self.interaction_events_individual[i][j][t] = e_ij, delta_t\n",
    "            \n",
    "            \n",
    "    def remove_node(self, i):\n",
    "        self.node_wise_events.pop(i,None)\n",
    "        for j, e_j_t in self.interaction_events_individual.items():\n",
    "            e_j_t.pop(i, None)\n",
    "        self.interaction_events_individual.pop(i,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b2e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(nn.Module):\n",
    "    def __init__(self, N_0, d_s):\n",
    "        super(Memory, self).__init__()\n",
    "        self.num_nodes = {t_0 : N_0}\n",
    "        self.d_s = d_s\n",
    "        self.mem = nn.GRU(d_h, d_h)\n",
    "        self.__init_memory__(N_0, d_s)\n",
    "    \n",
    "    def __init_memory__(self, N_0, d_s):\n",
    "        #self.register_buffer('S', torch.zeros((N_0, d_s)))\n",
    "        self.S  = nn.Parameter(torch.zeros((N_0, d_s)), requires_grad = False)\n",
    "        \n",
    "    def forward(self, S_next):\n",
    "        self.S = nn.Parameter(S_next, requires_grad = False)\n",
    "        \n",
    "    def add_node(self):\n",
    "        self.S = nn.Parameter(torch.cat([self.S, nn.Parameter(torch.zeros((1,self.d_s)))], dim = 0), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c2584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryUpdater(nn.Module):\n",
    "    def __init__(self, d_m, d_s):\n",
    "        super(MemoryUpdater, self).__init__()\n",
    "        \n",
    "        self.mem = nn.GRUCell(d_m, d_s)\n",
    "        \n",
    "    def forward(self, am, S):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        am : list( torch.tensor[d_m] ) \n",
    "        S : torch.tensor[N, d_s]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        S_next : torch.tensor[N, d_s]\n",
    "        \"\"\"\n",
    "        S_next = torch.ones_like(S)\n",
    "        for i, am_i in am.items():\n",
    "            x = am_i.unsqueeze(0)\n",
    "            h = S[i].unsqueeze(0)\n",
    "            S_next[i] = self.mem(x, h).squeeze(0)\n",
    "        return S_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26896f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageFunction(nn.Module):\n",
    "    def __init__(self, d_rm, d_m):\n",
    "        super(MessageFunction, self).__init__()\n",
    "        \n",
    "        self.d_rm = d_rm\n",
    "        self.d_m = d_m\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(d_rm, d_rm // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_rm // 2, d_m)\n",
    "        )\n",
    "    \n",
    "    def forward(self, raw_message):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ----------\n",
    "        interaction event\n",
    "            raw_message = [s_i_prev, s_j_prev, delta_t, e_ij]\n",
    "            s_i_prev : torch.tensor [d_s]\n",
    "            s_j_prev : torch.tensor [d_s]\n",
    "            delta_t : torch.tensor []\n",
    "            e_ij : torch.Tensor [d_e]\n",
    "            \n",
    "        node wise event\n",
    "            raw_message = [s_i_prev, t, v_i]\n",
    "            s_i : torch.tensor [d_s]\n",
    "            t : torch.tensor []\n",
    "            v_i : torch.Tensor [d_v]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction event\n",
    "            m_i : torch.tensor [d_s + d_s + 1 + d_e]\n",
    "            \n",
    "        node wise event\n",
    "            m_i : torch.tensor [d_s + 1 + d_v]\n",
    "        \"\"\"\n",
    "        rm_i = torch.cat(raw_message, dim = -1)\n",
    "        try:\n",
    "            m_i = self.MLP(rm_i)\n",
    "        except:\n",
    "            print(rm_i.shape)\n",
    "        return m_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786125ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageAggregator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MessageAggregator, self).__init__()\n",
    "        \n",
    "    def forward(self, om):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        om : dict( int : {torch.tensor[1] : torch.tensor[d_m]})\n",
    "             dict( i : {t : m})\n",
    "             \n",
    "        Returns\n",
    "        -------\n",
    "        m_agg : dict( int : torch.tensor[d_m] )\n",
    "                dict( i : m_agg_i)\n",
    "        \"\"\"\n",
    "        m_agg = dict()\n",
    "        for i, om_i in om.items():\n",
    "            m_i_agg = list()\n",
    "            for t, m_i_all in om_i.items():\n",
    "                for m_i in m_i_all:\n",
    "                    m_i_agg.append(m_i) \n",
    "            m_agg[i] = torch.stack(m_i_agg, dim = 0).mean(dim = 0)\n",
    "        return m_agg\n",
    "    \n",
    "def get_MessageAggregator(reduction):\n",
    "    if reduction == 'mean':\n",
    "        return MessageAggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a74932",
   "metadata": {},
   "outputs": [],
   "source": [
    "class time2vec(nn.Module):\n",
    "    def __init__(self, d_t):\n",
    "        super(time2vec, self).__init__()\n",
    "        self.lin = nn.Linear(1, d_t)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        t : torch.Tensor [1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        t2v : torch.Tensor [d_t]\n",
    "        \"\"\"\n",
    "        t2v = self.lin(t)\n",
    "        t2v = torch.cos(t2v)\n",
    "        return t2v\n",
    "    \n",
    "    def t_minus_tj(self, e, t):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        e : interaction_events_individual\n",
    "        t : torch.tensor[1]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        phi_t : dict( i : {j : phi(t - t_j)})\n",
    "        \"\"\"\n",
    "        phi_t = defaultdict(dict)\n",
    "        for i, e_ij in e.items():\n",
    "            for j, e_ij_t in e_ij.items():\n",
    "                t_j = list(e_ij_t.keys())[-1]\n",
    "                phi_t[i][j] = self(t - t_j)\n",
    "        return phi_t\n",
    "    \n",
    "    \n",
    "    def t0(self):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        -\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        t0 : torch.tensor [d_t]\n",
    "        \"\"\"\n",
    "        t0 = self(torch.tensor([0.]))\n",
    "        return t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3aa018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttention(nn.Module):\n",
    "    def __init__(self, d_q, d_k, d_v, d_h):\n",
    "        super(SingleHeadAttention, self).__init__()\n",
    "        \n",
    "        self.norm = torch.sqrt(torch.tensor(d_h).float())\n",
    "        self.W_q = nn.Linear(d_q, d_h)\n",
    "        self.W_k = nn.Linear(d_k, d_h)\n",
    "        self.W_v = nn.Linear(d_v, d_h)\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, K, V):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        Q : torch.tensor[n_q, d_q]\n",
    "        K : torch.tensor[n_k, d_k]\n",
    "        V : torch.tensor[n_v, d_v]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y : torch.tensor[n_q, d_h]\n",
    "        \"\"\"\n",
    "        Q = self.W_q(Q) \n",
    "        K = self.W_k(K)\n",
    "        V = self.W_v(V) \n",
    "        S = (Q @ K.T) / self.norm\n",
    "        A = nn.Softmax(-1)(S) \n",
    "        Y = A @ V            \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24f0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, k, d_q, d_k, d_v, d_h):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.heads = nn.ModuleList([\n",
    "            SingleHeadAttention(d_q, d_k, d_v, d_h)\n",
    "            for _ in range(k)\n",
    "        ])\n",
    "        self.lin = nn.Linear(k*d_h, d_h)\n",
    "        \n",
    "    def forward(self, Q, K, V):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        Q : torch.tensor[n_q, d_q]\n",
    "        K : torch.tensor[n_k, d_k]\n",
    "        V : torch.tensor[n_v, d_v]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y : torch.tensor[n_q, d_h]\n",
    "        \"\"\"\n",
    "        return self.lin(torch.cat([head(Q, K, V) for head in self.heads], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf72a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphAttention(nn.Module):\n",
    "    def __init__(self, l, k, n, d_c, d_h, d_t):\n",
    "        super(TemporalGraphAttention, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TemporalGraphAttentionLayer(k, n, d_c, d_h, d_t)\n",
    "            for _ in range(l)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, h, phi_t, phi_0, e):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        phi_t : dict( i : {j : phi(t - t_j)})\n",
    "        phi_0 : torch.tensor[d_t]\n",
    "        e : interaction_events_individual\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, phi_t, phi_0, e)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bce703c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, k, n, d_c, d_h, d_t):\n",
    "        super(TemporalGraphAttentionLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(k=k, d_q=d_h+d_t, d_k=d_c, d_v=d_c, d_h=d_h)\n",
    "        self.n = n\n",
    "        self.d_c = d_c\n",
    "        \n",
    "    def forward(self, h, phi_t, phi_0, e):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        phi_t : dict( i : {j : phi(t - t_j)})\n",
    "        phi_0 : torch.tensor[d_t]\n",
    "        e : interaction_events_individual\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        h_next : torch.tensor[N, d_h]\n",
    "        \"\"\"\n",
    "        h_next = list()\n",
    "        for i in range(len(h)):\n",
    "            C_i = torch.zeros((self.n, self.d_c))\n",
    "            C_list = list()\n",
    "            h_i = h[i]\n",
    "            e_i_t = e[i]\n",
    "            for j, e_ij_t in e_i_t.items():\n",
    "                t_e = list(e[i][j].keys())[-1]\n",
    "                c_j = torch.cat([h[j], phi_t[i][j], e_ij_t[t_e][0]])\n",
    "                C_list.append(c_j)\n",
    "            \n",
    "            if len(C_list) > 0:\n",
    "                C_i[:len(C_list),:] = torch.stack(C_list, dim = 0)\n",
    "            Q_i = torch.cat([h_i, phi_0], dim = 0)\n",
    "#             print(f'C:{C_i.shape}')\n",
    "#             print(f'Q:{Q_i.shape}')\n",
    "            h_i_next = self.attention(Q_i, K = C_i, V = C_i)        \n",
    "            h_next.append(h_i_next)\n",
    "        h_next = torch.stack(h_next, dim = 0)\n",
    "        return h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54f955c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPrediction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinkPrediction, self).__init__()\n",
    "\n",
    "    def pred_adj(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def pred_edge_ids(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "class LinkBinaryClassification(LinkPrediction):\n",
    "    def __init__(self):\n",
    "        super(LinkBinaryClassification, self).__init__()\n",
    "        \n",
    "    def prob_adj(self, h):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        p_e_ij_adj : torch.tensor[N, N]\n",
    "        \"\"\"\n",
    "        p_e_ij_adj = nn.Sigmoid()(h @ h.T)\n",
    "        p_e_ij_adj -= torch.diag_embed(p_e_ij_adj.diag())\n",
    "        return p_e_ij_adj\n",
    "    \n",
    "    \n",
    "    def prob_edge_index(self, h, edge_ids):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        edge_ids : list( (j,i), ... )\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        p_e_ij : torch.tensor[E, 1]\n",
    "        \"\"\"\n",
    "        p_e_ij = torch.stack([nn.Sigmoid()(h[j] @ h[i].T) for j,i in edge_ids],dim = 0)\n",
    "        return p_e_ij\n",
    "    \n",
    "    def pred_edge_index(self, h):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        h : torch.tensor[N, d_h]\n",
    "        edge_ids : list( (j,i), ... )\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pred_edge_index : torch.tensor[2, E]\n",
    "        \"\"\"\n",
    "        p_e_ij = self.prob_adj(h)\n",
    "        e_ij_pred_adj = torch.round(p_e_ij).detach().numpy()\n",
    "        pred_edge_index = torch.from_numpy(np.argwhere(e_ij_pred_adj)).T\n",
    "        return pred_edge_index\n",
    "    \n",
    "class LinkCategoricalClassification(LinkPrediction):\n",
    "    def __init__(self):\n",
    "        super(LinkCategoricalClassification, self).__init__()\n",
    "        \n",
    "    def pred_adj(self, h):\n",
    "        NotImplemented\n",
    "        # TODO\n",
    "    \n",
    "    def pred_edge_ids(self, h, edge_ids):\n",
    "        NotImplemented\n",
    "        # TODO\n",
    "        \n",
    "        \n",
    "class LinkRegression(LinkPrediction):\n",
    "    def __init__(self):\n",
    "        super(LinkRegression, self).__init__()\n",
    "        \n",
    "    def pred_adj(self, h):\n",
    "        NotImplemented\n",
    "        # TODO\n",
    "    \n",
    "    def pred_edge_ids(self, h, edge_ids):\n",
    "        NotImplemented\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b05536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag_embed(torch.ones((3,3)).diag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10fff58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Attributes\n",
    "----------\n",
    "\n",
    "\n",
    "Questions\n",
    "---------\n",
    "- Are edges directional? If yes, do we create (i,j) and (j,i)?\n",
    "- Do we aggregate node_wise_event-messages and interaction_event-messages together, if yes how, because different dim?\n",
    "- How do we make sure, that the concatenation of all neighbours in GAT is equally long, if node has few neighbours? \n",
    "  Just fill up to standard length with zeros?\n",
    "- what happens to nodes with degree 0 in the GAT layer? Just propagate the unmodified h = s+v through all layers?\n",
    "- I've modelled v_i = 0 as a deleted node and e_ij = 0 as a deleted edge and e_ij = 1 as a existing edge. \n",
    "  Is this good, or is it better allow nodes and edges to have all values (including 0)\n",
    "\"\"\"\n",
    "\n",
    "d_t = 1\n",
    "\n",
    "d_v = 2\n",
    "d_e = 1\n",
    "d_h = d_v\n",
    "d_s = d_v\n",
    "\n",
    "d_rm_v = d_s + 1 + d_v\n",
    "d_rm_e = 2*d_s + 1 + d_e\n",
    "d_m = 2\n",
    "\n",
    "l = 1\n",
    "k = 1\n",
    "d_q = d_h + d_t\n",
    "d_c = d_h + d_t + d_e\n",
    "n = 3\n",
    "\n",
    "TGN_hyperparams = dict()\n",
    "TGN_hyperparams['d_t'] = 1\n",
    "TGN_hyperparams['d_v'] = 2\n",
    "TGN_hyperparams['d_e'] = 1\n",
    "TGN_hyperparams['d_m'] = 2\n",
    "TGN_hyperparams['num_m'] = 3\n",
    "TGN_hyperparams['l'] = 1\n",
    "TGN_hyperparams['k'] = 1\n",
    "TGN_hyperparams['n'] = 3\n",
    "\n",
    "TGN_hyperparams['d_h'] = TGN_hyperparams['d_v']\n",
    "TGN_hyperparams['d_s'] = TGN_hyperparams['d_v']\n",
    "TGN_hyperparams['d_rm_v'] = TGN_hyperparams['d_s'] + 1 + TGN_hyperparams['d_v']\n",
    "TGN_hyperparams['d_rm_e'] = 2*TGN_hyperparams['d_s'] + 1 + TGN_hyperparams['d_e']\n",
    "TGN_hyperparams['d_q'] = TGN_hyperparams['d_h'] + TGN_hyperparams['d_t']\n",
    "TGN_hyperparams['d_c'] = TGN_hyperparams['d_h'] + TGN_hyperparams['d_t'] + TGN_hyperparams['d_e']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize Graph\n",
    "----------------\n",
    "N_0: initial number of nodes in the graph\n",
    "t_0: initial time\n",
    "\"\"\"\n",
    "N_0 = 3\n",
    "t_0 = torch.tensor([0.])\n",
    "\n",
    "v = torch.tensor([[0., 0.], [10., 10.], [20., 20.]])\n",
    "e_id = torch.tensor([[0, 1], [2, 1]]).T\n",
    "e = torch.tensor([[1.], [1.]])\n",
    "\n",
    "G = Data(v, e_id, e)\n",
    "G\n",
    "\n",
    "\"\"\"\n",
    "New events\n",
    "\"\"\"\n",
    "t_1 = torch.tensor([1.])\n",
    "v_i = torch.tensor([30., 30.])\n",
    "node_wise_events = [(3, v_i, t_1)]\n",
    "\n",
    "e_ij = torch.tensor([1.])\n",
    "t_2 = torch.tensor([1.])\n",
    "interaction_events = [((1,0), e_ij, t_2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e634679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model\n",
    "\"\"\"\n",
    "model = TGN(G, TGN_hyperparams)\n",
    "optimizer = Adam(model.parameters(), lr = 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
